{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this lab is to practice with basic features of several main python libraries for machine learning.\n",
    "In order to get access to the necessary functionality we will import some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading an example dataset\n",
    "\n",
    "\n",
    "For this introductory exercise, we will use a classic toy data set, Iris dataset wich is also a builtin dataset in scikit-learn library.\n",
    "\n",
    "The dataset was collected by botanist Edward Anderson and made famous by Ronald Fisher, one of the most prolific statisticians in history. Anderson carefully measured the anatomical properties of samples of three different species of iris, Iris setosa, Iris versicolor, and Iris virginica. The full data set is available as part of scikit-learn. \n",
    "The dataset can be downloaded also from this [repository](http://archive.ics.uci.edu/ml/machine-learning-databases/iris/)\n",
    "\n",
    "The dataset includes 150 observations of the iris flower specifying some measurements: \n",
    "\n",
    "- sepal length, sepal width, petal length and petal width together with its subtype:\n",
    "*Iris setosa*, *Iris versicolor*, *Iris virginica*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Terminology\n",
    "\n",
    "Each row is an observation (also known as : sample, example, instance, record)\n",
    "\n",
    "Each column is a feature (also known as: predictor, attribute, independent variable, regressor, covariate)\n",
    "\n",
    "#### Data as table\n",
    "\n",
    "A basic table is a two-dimensional grid of data, in which the rows represent individual elements of the dataset, and the columns represent quantities related to each of these elements. In general, we will refer to the rows of the matrix as *samples*, and the number of rows as n_samples and the the columns of the matrix as *features*, and the number of columns as n_features.\n",
    "\n",
    "Features matrix - This table layout makes clear that the information can be thought of as a two-dimensional numerical array or matrix, called the features matrix with shape [n_samples, n_features]\n",
    "\n",
    "Target array.- In addition to the feature matrix X, we also generally work with a label or *target array*, which by convention we will usually call *y*. The target array is usually one dimensional, with length n_samples, and is generally contained in a NumPy array or Pandas Series.\n",
    "\n",
    "The loader functions from sklearn return a dictionary-like object holding at least two items: an array of shape n_samples * n_features with key data and a numpy array of length n_samples, containing the target values, with key target.\n",
    "\n",
    "This data is stored in the `.data` member, which is a `(n_samples, n_features)`\n",
    "array.\n",
    "The labels or response variables (dependent variables) are stored in the *.target* member.  \n",
    "\n",
    "\n",
    "The datasets also contain a full description in their DESCR attribute and some contain feature_names and target_names. See the [dataset descriptions](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris) for details.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \"bunch\" object containing iris dataset and its attributes\n",
    "iris = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the iris dataset and its shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the names of the four features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the integers representing the species of each observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the encoding scheme for species; 0 = Setosa , 1=Versicolor, 2= virginica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each value we are predicting is the response (also known as: target, outcome, label, dependent variable)\n",
    "\n",
    "Requirements for working with data in scikit-learn:\n",
    "\n",
    "1) Features and response are separate objects\n",
    "\n",
    "2) Features and response should be numeric\n",
    "\n",
    "3)Features and response should be NumPy arrays\n",
    "\n",
    "4)Features and response should have specific shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the types of the features and response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the values for features (unpacking)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # subsetting the first 4 rows of the array (and all columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # subsetting the first 10 rows and the last 2 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Reading the data in a pandas dataframe\n",
    " \n",
    "Pandas is a Python library for data analysis. It offers a number of data exploration, cleaning and transformation operations that are critical in working with data in Python. Pandas build upon numpy and scipy providing easy-to-use data structures and data manipulation functions with integrated indexing. The main data structures pandas provides are ‘Series’ and ‘DataFrames’. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = None\n",
    "\n",
    " \n",
    "iris_df['Class'] = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the data using pandas library, we should check out what the content is, description using the following:\n",
    "\n",
    "* dataset.head()  -  getting the first 10 rows of the data set\n",
    "* dataset.tail()  -  gettinge out last 10 row of the data set\n",
    "* dataset.describe() - to get a statistical summary of the dataset\n",
    "* dataframe.sample(5) - pops up 5 random rows from the data set \n",
    "* dataframe.isnull().sum()  - checks out how many null info are on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the iris data frame on columns 'Sepal Length', 'Sepal Width' and store them in an ew dataframe object X_\n",
    "\n",
    "X_ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the value for 'Sepal Length' in the first record/ data example to a chosen value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the df X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the range of Sepal Length?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a summary statistics of the traget variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking species\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list with the values of traget variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering by label (species)\n",
    "# # extract a new data frame that contains all the records from species setosa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the petal length attribute versus petal width for the first 1o examples\n",
    "\n",
    "# Label the axes\n",
    "\n",
    "\n",
    "# label the figure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introspection; get the doc string for scatter function from the pyplot module\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a plot figure of width 12 units and height 9 units \n",
    "\n",
    "\n",
    "# Create an array of three colours, one for each species.\n",
    "#colors = np.array(['red', 'green', 'blue'])\n",
    "\n",
    "#Draw a Scatter plot for Sepal Length vs Sepal Width\n",
    "#nrows=1, ncols=2, plot_number=1\n",
    "# http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.subplot or plt.subplot?\n",
    "\n",
    "\n",
    "# http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More plotting examples at: http://matplotlib.org/examples/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the 'petal length' attribute versus 'petal width' using pandas plot function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data from a .csv file in a pandas dataframe\n",
    "\n",
    "import pandas as pd\n",
    "iris_filename = 'datasets-uci-iris.csv'\n",
    "iris = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test dataset  spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seed = 42\n",
    "\n",
    "# number of observations\n",
    "n = None\n",
    "print(n)\n",
    "is_train = None # Create an array of the given shape and populate it with\n",
    "                                   # random samples from a uniform distribution, and mask the numbers smaller than 0.7\n",
    "                                   # the result is a boolean vector\n",
    "print(sum(is_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = None  # boolean masking\n",
    "y_train = None\n",
    "X_test = None\n",
    "y_test = None\n",
    "print('Size of training features matrix:', X_train.shape)\n",
    "print('Size of training labels vector:', y_train.shape)\n",
    "print('Size of test features matrix :', X_test.shape)\n",
    "print('Size of test labels vector:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Train test dataset  spliting using  *model_selection* class from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# Split-out validation dataset\n",
    "array = None\n",
    "type(array)\n",
    "array.shape\n",
    "X = None\n",
    "Y = None\n",
    "validation_size = None\n",
    "seed = 7\n",
    "X_train_2, X_validation_2, Y_train_2, Y_validation_2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
