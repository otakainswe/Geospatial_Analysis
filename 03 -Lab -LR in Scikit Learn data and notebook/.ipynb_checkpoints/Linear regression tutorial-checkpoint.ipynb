{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression in Scikit -Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn is machine learning library for Python. It includes implementation of many machine learning algortihms such as clustering, classification and regression algorithms. Documentation of scikit-learn http://scikit-learn.org/stable/index.html gives an overview of all the algorithms available in this library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we implement our first linear regression model, we will introduce a new\n",
    "dataset, the Housing Dataset, which contains information about houses in the\n",
    "suburbs of Boston collected by D. Harrison and D.L. Rubinfeld in 1978. The Housing\n",
    "Dataset has been made freely available and can be downloaded from the UCI machine\n",
    "learning repository at https://archive.ics.uci.edu/ml/machine-learning-databases/housing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, your goal will be to use this data make predictions of the output given the input feature.\n",
    "\n",
    "### to be corrected\n",
    "You will predict the median value of owner occupied hauses ('MEDV') features such as average number of rooms per dwelling. Since the target variable here is quantitative, this is a regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import numpy and pandas as their standard aliases.\n",
    "* Read the file 'housing.csv' into a DataFrame df using the read_csv() function.\n",
    "* Using the metadata file 'housing.names', attach the corresponding name to each column.\n",
    "* Check the result using the method df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the housing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, it is important to explore your data before building models.\n",
    "* Use the pandas data frame methods to get informations about the size and the form of the dataset\n",
    "* Get a statistical summary of the dataset\n",
    "\n",
    "* Create a scatterplot matrix that allows us to visualize the pair-wise correlations the a subset of features ('INDUS', 'NOX', 'RM','LSTAT', 'MEDV') in this dataset in one place.\n",
    "* To plot the scatterplot matrix, we will use the pairplot function from the seaborn library\n",
    "(http://stanford.edu/~mwaskom/software/seaborn/), which is a Python library for drawing statistical plots based on matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before being able to fit our model using scikit-learn library, we need to bring it into the form needed by scikit-learn. This involves creating feature and target variable arrays. Furthermore, since you are going to use only one feature to begin with, you need to do some reshaping using NumPy's .reshape() method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create array X for the 'RM' feature and array y for the 'MEDV' target variable.\n",
    "* Reshape the arrays by using the .reshape() method and passing in (-1, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit & predict for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit a linear regression model, we are interested in those features that have a high\n",
    "correlation with our target variable MEDV. Looking at the preceding correlation\n",
    "matrix, we see that our target variable MEDV shows the largest correlation with\n",
    "the LSTAT variable (-0.74). However, as you might remember from the scatterplot\n",
    "matrix, there is a clear nonlinear relationship between LSTAT and MEDV. On the\n",
    "other hand, the correlation between RM and MEDV is also relatively high (0.70) and\n",
    "given the linear relationship between those two variables that we observed in the\n",
    "scatterplot, RM seems to be a good choice for an exploratory variable to introduce\n",
    "the concepts of a simple linear regression model in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will fit a linear regression and predict the value of a houses using just one feature.  In this exercise, you will use the 'RM' feature of *the housing* dataset. Since the goal is to predict houses' value, the target variable here is 'MEDV'. \n",
    "\n",
    "* Generate a scatter plot with 'RM' on the x-axis and 'MEDV' on the y-axis. As you can see, there is a strongly positive correlation, so a linear regression should be able to capture this trend.\n",
    "* Your task is to fit a linear regression and then predict the houses' prices, overlaying these predicted values on the plot to generate a regression line.\n",
    "* You will also compute and print the R2 score using sckit-learn's .score() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test split for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test sets are vital to ensure that the supervised learning model is able to generalize well to new data. This is equally true for linear regression models, as for classification  models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you will split the housing dataset into training and testing sets, and then fit and predict a linear regression over **all features**. In addition to computing the **R2** score, you will also compute the **Root Mean Squared Error (RMSE)**, which is another commonly used metric to evaluate regression models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import mean_squared_error from sklearn.metrics, and train_test_split from sklearn.model_selection.\n",
    "* Create feature and target arrays X (all features excepting 'MEDV') and y ('MEDV']\n",
    "* Using X and y, create training and test sets such that 30% is used for testing and 70% for training. Use a random state of 42.\n",
    "* Create a linear regression regressor called *reg_all*, fit it to the training set, and evaluate it on the test set.\n",
    "* Compute and print the R2 score using the *.score()* method on the test set.\n",
    "* Compute and print the *RMSE*. To do this, first compute the Mean Squared Error using the *mean_squared_error()* function with the arguments *y_test* and *y_pred*, and then take its square root using *np.sqrt()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a vital step in evaluating a model. It maximizes the amount of data that is used to train the model, as during the course of training, the model is not only trained, but also tested on all of the available data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will practice 5-fold cross validation on the *housing* data. By default, scikit-learn's cross_val_score() function uses R2 as the metric of choice for regression. Since you are performing 5-fold cross-validation, the function will return 5 scores. Your job is to compute these 5 scores and then take their average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import LinearRegression from *sklearn.linear_model* and *cross_val_score* from *sklearn.model_selection*.\n",
    "* Create a linear regression regressor called *reg*.\n",
    "* Use the *cross_val_score()* function to perform 5-fold cross-validation on X and y.\n",
    "* Compute and print the average cross-validation score. You can use NumPy's *mean()* function to compute the average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization I: Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that lasso performs regularization by adding to the loss function a penalty term of the absolute value of each coefficient multiplied by some alpha.\n",
    "\n",
    "As a result, the L1 regularization (penalizing the sum of the absolut values of the weights) has a sparcity effect, meaning that while shrinking the coefficients of certain features to 0, while preserving the most relevant features (performes feature selection).\n",
    "\n",
    "In this exercise, you will fit a lasso regression to the housing data you have been working with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import Lasso from sklearn.linear_model.\n",
    "* Instantiate a Lasso regressor with an alpha of 0.1 and specify normalize=True.\n",
    "* Fit the regressor to the data and compute the coefficients using the coef_ attribute.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization II: Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso is great for feature selection, but when building regression models, Ridge regression should be your first choice.\n",
    "\n",
    "If instead you took the sum of the squared values of the coefficients multiplied by some alpha - like in Ridge regression - you would be computing the L2 norm. In this task, you will practice fitting ridge regression models over a range of different alphas, and plot cross-validated R2 scores for each, using this function that we have defined for you, which plots the R2 score as well as standard error for each alpha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_plot(cv_scores, cv_scores_std):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(alpha_space, cv_scores)\n",
    "\n",
    "    std_error = cv_scores_std / np.sqrt(10)\n",
    "\n",
    "    ax.fill_between(alpha_space, cv_scores + std_error, cv_scores - std_error, alpha=0.2)\n",
    "    ax.set_ylabel('CV Score +/- Std Error')\n",
    "    ax.set_xlabel('Alpha')\n",
    "    ax.axhline(np.max(cv_scores), linestyle='--', color='.5')\n",
    "    ax.set_xlim([alpha_space[0], alpha_space[-1]])\n",
    "    ax.set_xscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry about the specifics of the above function works. The motivation behind this exercise is for you to see how the R2 score varies with different alphas, and to understand the importance of selecting the right value for alpha. You'll learn how to tune alpha in the next chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instantiate a Ridge regressor and specify normalize=True.\n",
    "* Inside the for loop:\n",
    "    * Specify the alpha value for the regressor to use.\n",
    "    * Perform 10-fold cross-validation on the regressor with the specified alpha. The data is available in the arrays X and y.\n",
    "    * Append the average and the standard deviation of the computed cross-validated scores. NumPy has been pre-imported for you as np.\n",
    "    * Use the display_plot() function to visualize the scores and standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
