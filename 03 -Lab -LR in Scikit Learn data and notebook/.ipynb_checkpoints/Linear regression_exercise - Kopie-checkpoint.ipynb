{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression in Scikit -Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn is machine learning library for Python. It includes implementation of many machine learning algortihms such as clustering, classification and regression algorithms. Documentation of scikit-learn http://scikit-learn.org/stable/index.html gives an overview of all the algorithms available in this library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we implement our first linear regression model, we will introduce a new\n",
    "dataset, the Housing Dataset, which contains information about houses in the\n",
    "suburbs of Boston collected by D. Harrison and D.L. Rubinfeld in 1978. The Housing\n",
    "Dataset has been made freely available and can be downloaded from the UCI machine\n",
    "learning repository at https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
    "\n",
    "For the purposes of this project, the following preprocessing steps have been made to the dataset:\n",
    "- 16 data points have an `'MEDV'` value of 50.0. These data points likely contain **missing or censored values** and have been removed.\n",
    "- 1 data point has an `'RM'` value of 8.78. This data point can be considered an **outlier** and has been removed.\n",
    "- The features `'RM'`, `'LSTAT'`, `'PTRATIO'`, and `'MEDV'` are essential. The remaining **non-relevant features** have been excluded.\n",
    "- The feature `'MEDV'` has been **multiplicatively scaled** to account for 35 years of market inflation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, your goal will be to use this data to **learn/ train** a linear model that will allow to make predictions about the monetary value of a home, knowing some particular features.  \n",
    "You will predict the median value of owner occupied hauses ('MEDV') based on the available features in the dataset, such as average number of rooms per dwelling, etc.. Since the target variable here is quantitative, this is a regression problem.\n",
    "Moreover, you will evaluate the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0: Importing necessary modules\n",
    "\n",
    "Import numpy and pandas as their standard aliases, as well scikit-learn library (sklearn).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matpoltlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-54142fa6bc7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatpoltlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matpoltlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matpoltlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Reading the data\n",
    "\n",
    "\n",
    "Before staring to build and train a linear model for houses price prediction with sklearn, you need to:\n",
    "- import the data provided as 'housing.csv' (HINT: pd.read_csv())\n",
    "- get a quick inspection of the data unsing known pandas methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.575</td>\n",
       "      <td>4.98</td>\n",
       "      <td>15.3</td>\n",
       "      <td>504000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.421</td>\n",
       "      <td>9.14</td>\n",
       "      <td>17.8</td>\n",
       "      <td>453600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.185</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.8</td>\n",
       "      <td>728700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.998</td>\n",
       "      <td>2.94</td>\n",
       "      <td>18.7</td>\n",
       "      <td>701400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.147</td>\n",
       "      <td>5.33</td>\n",
       "      <td>18.7</td>\n",
       "      <td>760200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RM  LSTAT  PTRATIO      MEDV\n",
       "0  6.575   4.98     15.3  504000.0\n",
       "1  6.421   9.14     17.8  453600.0\n",
       "2  7.185   4.03     17.8  728700.0\n",
       "3  6.998   2.94     18.7  701400.0\n",
       "4  7.147   5.33     18.7  760200.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('housing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Task 2a: Exploring the housing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, it is important to explore your data before building models.\n",
    "* Use the pandas data frame methods to get informations about the size and the form of the dataset\n",
    "* Get a statistical summary of the dataset\n",
    "\n",
    "* Create a scatterplot matrix that allows us to visualize the pair-wise correlations a subset of features ( 'RM','LSTAT', 'PTRATIO', 'MEDV') in this dataset in one place.\n",
    "* To plot the scatterplot matrix, we will use the pairplot function from the seaborn library\n",
    "(http://stanford.edu/~mwaskom/software/seaborn/), which is a Python library for drawing statistical plots based on matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ 3 lines of code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set (style = 'whitegrid', context = 'notebook')\n",
    "_ = sns.pairplot(data, size = 2.5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Task 2b: Calculate statistics of the target variable\n",
    " Store the 'MEDV' in a variable 'prices'.\n",
    " Calculate the minimum, maximum, mean, median, and standard deviation of 'MEDV', which is stored in `prices`.\n",
    "  - Store each calculation in their respective variable.\n",
    " These statistics will be extremely important later on to analyze various prediction results from the constructed model. \n",
    " Use numpy library  to perform the necessary calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Minimum price in the data\n",
    "minimum_price = None\n",
    "\n",
    "# Maximum price in the data\n",
    "maximum_price = None\n",
    "\n",
    "#  Mean price in the data\n",
    "mean_price = None\n",
    "\n",
    "#  Median price in the data\n",
    "median_price = None\n",
    "\n",
    "# Standard deviation of prices in the data\n",
    "std_price = None\n",
    "\n",
    "# Show the calculated statistics\n",
    "print(\"Statistics for Boston housing dataset:\\n\")\n",
    "print(\"Minimum price: ${}\".format(minimum_price)) \n",
    "print(\"Maximum price: ${}\".format(maximum_price))\n",
    "print(\"Mean price: ${}\".format(mean_price))\n",
    "print(\"Median price ${}\".format(median_price))\n",
    "print(\"Standard deviation of prices: ${}\".format(std_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3:  Feature Observation\n",
    "\n",
    "As a reminder, we are using three features from the Boston housing dataset: `'RM'`, `'LSTAT'`, and `'PTRATIO'`. For each data point (neighborhood):\n",
    "- `'RM'` is the average number of rooms among homes in the neighborhood.\n",
    "- `'LSTAT'` is the percentage of homeowners in the neighborhood considered \"lower class\" (working poor).\n",
    "- `'PTRATIO'` is the ratio of students to teachers in primary and secondary schools in the neighborhood.\n",
    "\n",
    "\n",
    "** Using your intuition, for each of the three features above, do you think that an increase in the value of that feature would lead to an **increase** in the value of `'MEDV'` or a **decrease** in the value of `'MEDV'`? Justify your answer for each.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Your answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Preparing the data as input for sklearn \n",
    "\n",
    "Since the main goal of this project is to construct a working model which has the capability of predicting the value of houses, you will need to separate the dataset into **features** and the **target variable**. They must be nupy array as input for sklearn API.\n",
    "\n",
    "\n",
    "The **features**, `'RM'`, `'LSTAT'`, and `'PTRATIO'`, give us quantitative information about each data point. The **target variable**, `'MEDV'`, will be the variable we seek to predict. \n",
    "\n",
    "To fit a linear regression model, we are interested in those features that have a high\n",
    "correlation with our target variable MEDV. Looking at the preceding correlation\n",
    "matrix, we see that our target variable MEDV shows the largest correlation with\n",
    "the LSTAT variable (-0.74). However, as you might remember from the scatterplot\n",
    "matrix, there is a clear nonlinear relationship between LSTAT and MEDV. On the\n",
    "other hand, the correlation between RM and MEDV is also relatively high (0.70) and\n",
    "given the linear relationship between those two variables that we observed in the\n",
    "scatterplot, RM seems to be a good choice for an exploratory variable to introduce\n",
    "the concepts of a simple linear regression model in the following section.\n",
    "\n",
    "-  store the 'RM' feature in a variable X\n",
    "-  store the 'MEDV' feature in a variable y\n",
    "-  reshape the resulted arrays using the .numpy .reshape() method, passing (-1,1) as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = None  # features matrix\n",
    "\n",
    "y = None # traget vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Fit a linear regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit a linear regression model, we are interested in those features that have a high\n",
    "correlation with our target variable MEDV. Looking at the preceding correlation\n",
    "matrix, we see that our target variable MEDV shows the largest correlation with\n",
    "the LSTAT variable (-0.74). However, as you might remember from the scatterplot\n",
    "matrix, there is a clear nonlinear relationship between LSTAT and MEDV. On the\n",
    "other hand, the correlation between RM and MEDV is also relatively high (0.70) and\n",
    "given the linear relationship between those two variables that we observed in the\n",
    "scatterplot, RM seems to be a good choice for an exploratory variable to introduce\n",
    "the concepts of a simple linear regression model in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will fit a linear regression and predict the value of a houses using just one feature.  In this exercise, you will use the 'RM' feature of *the housing* dataset. Since the goal is to predict houses' value, the target variable here is 'MEDV'. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from sklerarn.linear_model the  Linear Regression module\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a linear regression object\n",
    "lm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the fit method on your lm object to train the model, providing as arguments the feature and target \n",
    "_ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the coeficients of your model using the coef_ attribute of your trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and print the R2 score using sckit-learn's .score() method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 - Predicting Selling Prices\n",
    "\n",
    "Imagine that you were a real estate agent in the Boston area looking to use this model to help price homes owned by your clients that they wish to sell. You have collected the following information from three of your clients:\n",
    "\n",
    "| Feature | Client 1 | Client 2 | Client 3 |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| Total number of rooms in home | 5 rooms | 4 rooms | 8 rooms |\n",
    "| Neighborhood poverty level (as %) | 17% | 32% | 3% |\n",
    "| Student-teacher ratio of nearby schools | 15-to-1 | 22-to-1 | 12-to-1 |\n",
    "\n",
    "* What price would you recommend each client sell his/her home at? \n",
    "* Do these prices seem reasonable given the values for the respective features? \n",
    "\n",
    "**Hint:** Use the statistics you calculated in the **Data Exploration** section to help justify your response.  Of the three clients, client 3 has has the biggest house, in the best public school neighborhood with the lowest poverty level; while client 2 has the smallest house, in a neighborhood with a relatively high poverty rate and not the best public schools.\n",
    "\n",
    "Run the code block below to have your optimized model make predictions for each client's home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a matrix for client data\n",
    "client_data = [[5, 17, 15], # Client 1\n",
    "               [4, 32, 22], # Client 2\n",
    "               [8, 3, 12]]  # Client 3\n",
    "\n",
    "# Show predictions\n",
    "for i, price in enumerate(lm.predict(client_data)):\n",
    "    print(\"Predicted selling price for Client {}'s home: ${:,.2f}\".format(i+1, price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART II\n",
    "### Train/test split for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test sets are vital to ensure that the supervised learning model is able to generalize well to new data. This is equally true for linear regression models, as for classification  models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you will split the housing dataset into training and testing sets, and then fit and predict a linear regression over **all features**. In addition to computing the **R2** score, you will also compute the **Root Mean Squared Error (RMSE)**, which is another commonly used metric to evaluate regression models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import mean_squared_error from sklearn.metrics, and train_test_split from sklearn.model_selection.\n",
    "* Create feature and target arrays X (all features excepting 'MEDV') and y ('MEDV')\n",
    "* Using train_test_split(X,y), create training and test (X_train, X_test, y_train, y_test) sets such that 30% is used for testing and 70% for training. Use a random state of 42.\n",
    "* Create a linear regression regressor called *reg_all*, fit it to the training set, and evaluate it on the test set.\n",
    "* Compute and print the R2 score using the *.score()* method on the test set.\n",
    "* Compute and print the *RMSE*. To do this, first compute the Mean Squared Error using the *mean_squared_error()* function with the arguments *y_test* and *y_pred*, and then take its square root using *np.sqrt()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = None\n",
    "X = None # HINT use .drop with the data drop the column 'MEDV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = None\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lin reg obj\n",
    "reg_all = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the regressor on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "y_pred = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print R^2 score and RMSE\n",
    "R_2 = None                  # Hint use .score on regressor object with X_test. y_test\n",
    "\n",
    "print('R^2: {}'.format())\n",
    "\n",
    "# Compute and print rmse\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
